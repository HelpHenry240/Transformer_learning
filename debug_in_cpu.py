import torch
import torch.nn as nn
# ç¡®ä¿ä½ çš„æ–‡ä»¶å¤¹ç»“æ„æ˜¯æ­£ç¡®çš„ï¼Œä¸”åŒ…å« __init__.py
from models.transformer import Transformer 

def make_dummy_mask(src, tgt):
    """
    åˆ›å»ºä¸€ä¸ªç®€æ˜“çš„ Mask ç”¨äºæµ‹è¯•
    src_mask: [Batch, 1, 1, SrcLen] - é®æŒ¡ padding
    tgt_mask: [Batch, 1, TgtLen, TgtLen] - é®æŒ¡æœªæ¥æ—¶åˆ» (look-ahead)
    """
    # è¿™é‡Œä¸ºäº†è·‘é€šä»£ç ï¼Œæˆ‘ä»¬æš‚æ—¶åˆ›å»ºå…¨ 1 çš„ mask (å³ä¸é®æŒ¡ä»»ä½•ä¸œè¥¿ï¼Œé™¤äº† pad)
    # å®é™…é¡¹ç›®ä¸­ä½ éœ€è¦æ ¹æ® padding value (æ¯”å¦‚ 0) æ¥ç”Ÿæˆ mask
    
    # Src Mask: å‡è®¾ src ä¸­ä¸º 0 çš„æ˜¯ padding
    src_mask = (src != 0).unsqueeze(1).unsqueeze(2) 
    
    # Tgt Mask: ç”Ÿæˆä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µï¼Œé˜²æ­¢çœ‹åˆ°æœªæ¥
    tgt_len = tgt.size(1)
    tgt_mask = torch.tril(torch.ones((tgt_len, tgt_len))).expand(
        tgt.size(0), 1, tgt_len, tgt_len
    ).type_as(src_mask)
    
    return src_mask, tgt_mask

def run_debug():
    print("----- å¼€å§‹ Transformer æœ¬åœ°é€»è¾‘éªŒè¯ -----")

    # 1. å®šä¹‰è¶…å‚æ•° (ä½¿ç”¨å°å‚æ•°ä»¥é€‚åº” CPU)
    BATCH_SIZE = 2
    SEQ_LEN = 10
    SRC_VOCAB_SIZE = 100
    TGT_VOCAB_SIZE = 120
    D_MODEL = 64       # æ­£å¸¸æ˜¯ 512ï¼Œæœ¬åœ°ç”¨ 64 å¤Ÿäº†
    N_LAYERS = 2       # å±‚æ•°
    HEADS = 4          # æ³¨æ„ï¼šD_MODEL å¿…é¡»èƒ½è¢« HEADS æ•´é™¤ (64/4=16)
    
    device = torch.device('cpu') # å¼ºåˆ¶ä½¿ç”¨ CPU

    # 2. å®ä¾‹åŒ–æ¨¡å‹
    try:
        model = Transformer(
            src_vocab_size=SRC_VOCAB_SIZE, 
            tgt_vocab_size=TGT_VOCAB_SIZE, 
            d_model=D_MODEL, 
            N=N_LAYERS, 
            heads=HEADS
        ).to(device)
        print("âœ… æ¨¡å‹å®ä¾‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹å®ä¾‹åŒ–å¤±è´¥: {e}")
        return

    # 3. æ„é€ ä¼ªæ•°æ® (Dummy Data)
    # è¾“å…¥: [Batch, SeqLen] çš„æ•´æ•°ç´¢å¼•
    src = torch.randint(1, SRC_VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(device)
    tgt = torch.randint(1, TGT_VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(device)

    # æ„é€ ç®€å•çš„ Mask
    src_mask, tgt_mask = make_dummy_mask(src, tgt)
    
    print(f"è¾“å…¥ Src å½¢çŠ¶: {src.shape}")
    print(f"è¾“å…¥ Tgt å½¢çŠ¶: {tgt.shape}")

    # 4. å‰å‘ä¼ æ’­ (Forward Pass)
    try:
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ model.forward(src, tgt, src_mask, tgt_mask)
        output = model(src, tgt, src_mask, tgt_mask)
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"è¾“å‡º Output å½¢çŠ¶: {output.shape}") 
        
        # éªŒè¯è¾“å‡ºç»´åº¦ï¼šåº”è¯¥æ˜¯ [Batch, SeqLen, Tgt_Vocab_Size]
        expected_shape = (BATCH_SIZE, SEQ_LEN, TGT_VOCAB_SIZE)
        assert output.shape == expected_shape, f"ç»´åº¦é”™è¯¯ï¼ŒæœŸæœ› {expected_shape}ï¼Œå®é™… {output.shape}"
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        # æ‰“å°è¯¦ç»†é”™è¯¯æ ˆå¯¹äº debug å¾ˆæœ‰ç”¨
        import traceback
        traceback.print_exc()
        return

    # 5. åå‘ä¼ æ’­æµ‹è¯• (Backward Pass)
    # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†ç¡®ä¿æ¢¯åº¦é“¾æ²¡æœ‰æ–­ï¼Œæ²¡æœ‰å‡ºç° inplaceæ“ä½œé”™è¯¯
    try:
        # å‡è®¾æ ‡ç­¾æ˜¯ tgt å‘åç§»ä¸€ä½ (è¿™é‡Œä¸ºäº†æµ‹è¯•ç›´æ¥ç”¨éšæœºæ•°)
        # å±•å¹³ output ä»¥è®¡ç®— CrossEntropy: [Batch*SeqLen, Vocab]
        output_flat = output.view(-1, TGT_VOCAB_SIZE)
        target_flat = torch.randint(0, TGT_VOCAB_SIZE, (BATCH_SIZE * SEQ_LEN,)).to(device)
        
        criterion = nn.CrossEntropyLoss()
        loss = criterion(output_flat, target_flat)
        
        model.zero_grad()
        loss.backward()
        print(f"âœ… åå‘ä¼ æ’­æˆåŠŸ (Loss: {loss.item():.4f})")
        print("ğŸ‰ æ­å–œï¼Transformer æ¨¡å‹æ ¸å¿ƒé€»è¾‘é€šè¿‡æµ‹è¯•ï¼")
        
    except RuntimeError as e:
        print(f"âŒ åå‘ä¼ æ’­å¤±è´¥ (é€šå¸¸æ˜¯ç»´åº¦ä¸åŒ¹é…æˆ– inplace é”™è¯¯): {e}")

if __name__ == '__main__':
    run_debug()